{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf100
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww13220\viewh10320\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \
dataset_directory = "./ohsumed-first-20000-docs"\
dataset_limit     = 10\
\
\'97 \
\
def load_files_absolutes_paths(path, get_absolute_path=False):\
    files_paths = []\
    for root, dirs, files in os.walk(path):\
        for file in files:\
            if file[0] != ".":\
                files_paths.append(os.path.abspath(root + "/" + file) if get_absolute_path else file)\
    return files_paths\
\
\'97 \
\
dataset_urls = load_files_absolutes_paths(dataset_directory, get_absolute_path=True)[:dataset_limit]\
\
\'97 \
\
dataset = []\
ponctuation = "\\n\\t!?<>:,;.()[]\{\}\\\\/_&\\"'-=+*"\
\
for url in dataset_urls:\
    file = open(url, 'r')\
    doc = file.read()\
    for p in ponctuation:\
        doc = doc.replace(p, ' ')\
    doc = doc.split(' ')\
    doc = list\
    dataset.append(doc)\
    file.close()\
print(["%d words" % len(x) for x in dataset])}